# 5. Managing the Test Activities

> policy strategy plan (from high to low)
> plan is per project
> policy & strategy are higher levels

## 5.1. Test Planning

### 5.1.1. Purpose and Content of a Test Plan

> A test plan accomplishes the the following: \
1. Document the means && schedule for achieving test objectives.
1. Ensure that the performed test meets the established criteria.
1. Demonstrates that testing will adhere to the existing test policy && strategy.

> Content of a test plan: \
1. Context of testing &rarr; scope, test objectives, test basis.
1. Assumptions & constraints of the test project.
1. Stakeholders &rarr; roles, responsibilities, relevance to testing, hiring & training needs.
1. Communication &rarr; forms and frequency of communication, documentation templates.
1. Risk register &rarr; product & project risks.
1. Test approach &rarr; test levels, types, techniques, deliverables, entry/exit criteria, independence of testing, test data/environment requirements, deviations from organizational test policy, test strategy.
1. Budget & schedule.

### 5.1.2. Tester's Contribution to Iteration & Release Planning

> Release Planning: looks ahead of the release of a product, defines & redefines the **product backlog [list of all the project's user stories]**, and may involve refining larger user stories into a set of smaller user stories + **it serves as the basis for the test approach & test plan across all iterations**

> Roles of testers participating in Release Planning: \
1. writing testable user stories & acceptance criteria,
1. participate in project and quality risk analyses,
1. estimate test effort associated with user stories, 
1. determine the test approach,
1. plan the testing for the release.

> Iteration Planning: looks ahead to the end of a single iteration, is concerned with **iteration backlog [list of user stories for this iteration].**

> Roles of testers participating in Iteration Planning: \
1. detailed risk analysis of user stories,
1. determine the testability of user stories,
1. break down user stories into testing tasks,
1. estimate test effort fr all testing tasks,
1. identify & refine functional and non-functional aspects of the test object.

### 5.1.3. Entry Criteria & Exit Criteria

> Entry Criteria: define the preconditions for undertaking a given activity.
> If entry criteria are not met, **the activity will be more difficult, time-consuming, costly, and riskier.**


> Exit Criteria: define what must be achieved in order to declare an activity completed.

> **Entry & Exit criteria should be defined for each test level & will differ based on test objectives.**

> Typical Entry Criteria: \
1. availability of resources &rarr; people, tools, environments, test data, budget, time.
1. availability of testware &rarr; test basis, testable requirements, user stories, test cases.
1. initial quality level of a test object &rarr; all **smoke tests** have passed.

> Typical Exit Criteria: \
1. measures of thoroughness &rarr; achieved level of coverage, number of unresolved defects, defect density, number of failed test cases.
1. completion criteria &rarr; planned tests have been executed, static testing has been performed, all defects found are reported, all regression tests are automated.

> **Running out of time or budget can also be viewed as valid exit criteria even without other exit criteria being satisfied.**

> In Agile SD, exit criteria is called **Definition of Done**.

> In Agile SD, entry criteria is called **Definition of Ready.**

### 5.1.4. Estimation Techniques

> Test Effort Estimation: involves predicting the amount of test-related work needed to meet the objectives of a test project. **must be clear to stakeholders with estimation prone to margin of error**

> Estimation Based on Ratios: \
1. metrics-based technique,
1. figures are collected from previous projects within the organization; making it possible to derive standard ratios for similar projects.
1. best source in the estimation process.

> Extrapolation: \
1. metric-based technique.
1. measurements are made as early as possible in the current project to gather data.
1. with enough observations, the required effort for the remaining work can be approximated by extrapolating the data.
1. this method is suitable for **iterative SDLCs.**

> Wideband Delphi: \
1. iterative & expert-based technique.
1. experts make **experience-based estimations**.
1. each expert estimates the effort in isolation THEN the results are collected, discussed, then if some estimations deviated the process is **repeated based on feedback from the discussion until common ground is reached.**
1. **Planning Poker** is a variant of Wideband Delphi used in Agile SD [estimates are made using cards with numbers that represent the effort size].

> Three-point Estimation: \
1. expert-based technique.
1. 3 estimations are made by experts &rarr; most optimistic estimation [a], most likely estimation [m], and the most pessimistic estimation [b].
1. The final estimation [e] is the weighed arithmetic mean of the other estimations.
	```
	E = (a + 4m + b) / 6
	```
1. The advantage of this technique is that it allows experts to calculate the measurement error **SD**:
	```
	SD = (b - a) / 6
	```

### 5.1.5. Test Case Prioritization
> Test Case Prioritization Strategy: \
1. Risk-based prioritization &rarr; order of test execution is based on the results of risk analysis. Test cases covering the most important risks are executed first.
1. Coverage-based Prioritization &rarr; order of test execution is based on coverage [aka statement/branch coverage]. Tests achieving the highest coverage are executed first. **Another variant called `Additional Coverage Prioritization`, test case that achieves the highest coverage is executed first THEN THE NEXT TEST CASE TO BE EXECUTED IS THE ONE THE ACHIEVES THE HIGHEST ADDITIONAL COVERAGE.**
1. Requirements-based Prioritization &rarr; order of execution is based on the priorities of the requirements that are covered by a test case. **Requirement priorities are defined by by stakeholders.**

> Ideally, test cases would be ordered to run based on their priority level. **However,** this will not happen if the test cases have dependencies on one another.

> Order of test execution must take into account the **availability of resources.**


