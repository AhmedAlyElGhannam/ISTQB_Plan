# Chapter Three

## 3.1. Static Testing Basics

### 3.1.1. Work Products Examined by Static Testing
> Almost all work products can be examined using Static Testing, including: (they need some sort of reference for that)
1. requirements specifications documents,
1. source code,
1. test plans,
1. test cases,
1. product backlog items,
1. test charters,
1. project documentation,
1. contracts & models.

> Work products that cannot be examine via Static Testing: *3rd party executable code (due to legal reasons)*.

### 3.1.2. Value of Static Testing
> Static testing can detect defects in the earliest phases of SDLC; fulfilling the principle of early testing.
> Static testing can detect defects that cannot be detected by dynamic testing like:
1. unreachable code,
1. design patterns not implemented as desired,
1. defects in non-executable work products.

> Static testing provides the ability to *evaluate the quality of + build confidence in* work products.
> By verifying the documented requirements, the stakeholders can make sure that deez requirements describe their actual needs. (creating a shared understanding among them + improved communication); this is why **it is important to involve stakeholders in static analysis.**

> Even if reviews can be costly to implement, they are cheaper overall than when no reviews are implement them (because of the time/effort/cost to fix defect later and yadeyadeyada)

> *Code defects* can be detected **much more efficiently** than in dynamic testing.

### 3.1.3. Differences Between Static Testing & Dynamic Testing
1. Static & Dynamic testing can both lead to detection of defects, *but there are some defects that can only be found only via static testing or dynamic testing.*
1. Static testing *finds defects directly*, while dynamic testing *causes failures from which the associated defects are determined through subsequent analysis*.
1. Static testing may more easily detect defects that *lay on paths through the code that are rarely executed or hard to reach* using dynamic testing.
1. Static testing **can be** applied to *non-executable work products*, while dynamic testing **can ONLY be** applied to *executable work products.*
1. Static testing can be used to *measure quality characteristics* that are **not dependent on executing code** (like maintainability), while dynamic testing can be used to *measure quality characteristics* that are **dependent on executing code** (like performance efficiency).

> Defects that are easier/cheaper to find through static testing:
1. Defects in **requirements** (inconsistencies, ambiguities, contradictions, omissions, inaccuracies, duplications)
1. Defects in **design** (inefficient database structures, poor modularization)
1. Defects in **code** (variables with undefined values, undeclared variables, unreachable/duplicated code, excessive code complexity)
1. **Deviations from standards** (not sticking to a naming convention)
1. **Incorrect interface specs [?!!]** (mismatched number, type, order of parameters)
1. **Specific types of security vulnerabilities** (buffer overflows)
1. **Gaps/inaccuracies in test basis coverage** (missing tests for an acceptance criterion)

## 3.2. Feedback and Review Process
### 3.2.1. Benefits of Early and Frequent Stakeholder Feedback
> If there is little stakeholder involvement during SDLC:
1. the product being developed might not meet the stakeholders' expectations,
> Failing to deliver to stakeholders can result in:
1. costly rework,
1. missed deadlines,
1. blame games,
1. might even lead to an epic project failure.

> Frequent stakeholder feedback can prevent misunderstandings about requirements and ensure that changes to requirements are understood and implemented earlier.

### 3.2.2. Review Process Activities
> The size of work products is **too large** to be covered by a single review. \
> Activities of the review process are:
1. Planning &rarr; scope of review [purpose + work product to be reviewed] + quality characteristics to be evaluated + areas to focus on + exit criteria + supporting info [standard + effor + timeframes for review].
1. Review Initiation &rarr; make sure that everyone/everything involved is ready to start the review and knows their role/responsibilities.
1. Individual Review [performed by every reviewer] &rarr; assesses the quality of the work product under review + identifies anomalies, recommendations, questions by applying review technique(s) **[checklist-based || scenario-based]** as provided by ISO/IEC 20246 standard.
1. Communication and Analysis &rarr; analysing anomalies and discussing the appropriate actions to solve them (they do not have to be defects per se)
1. Fixing and Reporting &rarr; A defect report must be created for every defect so that corrective action can be taken.

### 3.2.3. Roles and Responsibilities in Reviews
> Principle Roles + Their Responsibilities:
1. Manager &rarr; decides what to be reviewed + provides resources [staff & time for review]
1. Author &rarr; creates & fixes the work product under review.
1. Moderator [aka Facilitator] &rarr; ensures effective running of review meetings [mediation + time management + safe environment for speaking freely]
1. Scribe [aka Recorder] &rarr; records everything during review meeting [decisions + found anomalies]
1. Reviewer &rarr; performs reviews **duh!** + can be *someone working on the project*, *subject matter expert*, *stakeholder*.
1. Review Leader &rarr; decides who will be involved in a review + organizes when/where the review will take place.

### 3.2.4. Review Types **VIMP**
> Required level of review formality **depends on the type of SDLC being followed, maturity of development process, criticality/complexity if the work product being reviewed, legal/regulatory requirements, and the need for an audit trail**. \
> The same work product can be reviewed using different review types. \
> Review type is selected based on *project needs, available resources, work product type and risks, business domain, and company culture.* \
> Review Types:
1. Informal review &rarr; do not follow a defined process + do not require a formal documented output. **its main objective is detecting anomalies.**
1. Walkthrough [led by the author] &rarr; evaluates quality && builds confidence + **educates reviewers** + generates new ideas + enables the detection of anomalies. *reviewers might perform an individual review before walkthough but it is `not required`*
1. Technical Review [performed by *technical reviewers* and led by a **moderator**] &rarr; make decisions regarding technical problems + detect anomalies + evaluate quality + build confidence + generate new ideas.
1. Inspection [most formal type] &rarr; find the maximum number of anomalies. **author cannot act as review leader or scribe.**

### 3.2.5. Success Factors for Reviews
1. Defining clear objectives + exit criteria.
1. Choosing appropriate review type to achieve required objectives/type of work product/review participants/project needs.
1. Conducting reviews on smol chunks.
1. Providing feedback from reviews to stakeholders && author to improve the process.
1. Providing time for participants to prepare a review.
1. Support from management for the review process.
1. Making reviews part of the organization's culture to promote learning and process improvement.
1. Facilitating meetings.
